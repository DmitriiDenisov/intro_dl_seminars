{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy_of_train_notebook_(2).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitriiDenisov/intro_dl_seminars/blob/master/week3/Faces_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "DarZnvmuOiac"
      },
      "cell_type": "markdown",
      "source": [
        "## Сегментация. Выделение человека по фотографии"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "7zyay1nHL93c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Сначала сделаем загрузку данных:\n",
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/DmitriiDenisov/intro_dl_seminars/master/setup_colab.py -O setup_google_colab.py\n",
        "from setup_google_colab import setup_week3\n",
        "setup_week3()\n",
        "!mkdir data/try_prediction\n",
        "!mkdir output_reduced/output_try_prediction\n",
        "!mkdir output_reduced/test_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZoXakkwwfgrp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Сначала сделаем импорты:"
      ]
    },
    {
      "metadata": {
        "id": "22LSL6XQgTdb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import numpy as np\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dropout, BatchNormalization, Activation, Add, Flatten, Dense, Reshape, UpSampling2D, MaxPooling2D,  Conv2D, Conv2DTranspose, concatenate, Lambda\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img#,save_img\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from matplotlib.pyplot import subplots_adjust\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GBpK_7YPgese",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Считываем данные. Это фотографии и маски"
      ]
    },
    {
      "metadata": {
        "id": "kCOf1Fouv0lS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#1. Данные"
      ]
    },
    {
      "metadata": {
        "id": "RF9jxXkXgmQa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dir = 'data/train/'\n",
        "images = [np.array(load_img(join(train_dir, f), grayscale=False)) / 255\n",
        "                for f in listdir(train_dir) if isfile(join(train_dir, f))]\n",
        "masks_dir = 'data/train_mask/'\n",
        "masks = [np.array(load_img(join(masks_dir, f), grayscale=True)) / 255\n",
        "               for f in listdir(masks_dir) if isfile(join(masks_dir, f))]\n",
        "\n",
        "images = np.array(images)\n",
        "masks = np.array(masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pZgzgSV-CuOE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Посмотрим на датасет. Рандомно выберем n фотографий и соответствующие ответы к ним:"
      ]
    },
    {
      "metadata": {
        "id": "47pheWkzgo_d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SIZE_OF_RANDOM_CHOOSE = 10\n",
        "# Считыавем тестовые изображения:\n",
        "train_dir = 'data/train'\n",
        "masks_dir = 'data/train_mask'\n",
        "\n",
        "train_file_names = [f[:f.find('.')] for f in listdir(train_dir) if isfile(join(train_dir, f))]\n",
        "masks_file_names = [f[:f.find('.')] for f in listdir(masks_dir) if isfile(join(masks_dir, f))]\n",
        "\n",
        "train_file_names, train_images = zip(*sorted(zip(train_file_names, images)))\n",
        "masks_file_names, masks_images = zip(*sorted(zip(masks_file_names, masks)))\n",
        "\n",
        "# Выбираем рандомно несколько изображений:\n",
        "temp_ = np.array(list(range(0, len(train_file_names)))).reshape((-1, 3))\n",
        "b = temp_[np.random.choice(temp_.shape[0], SIZE_OF_RANDOM_CHOOSE, replace=False), :].flatten()\n",
        "random_choose_test_file_names = np.array(train_file_names)[b]\n",
        "random_choose_train_images = np.array(train_images)[b]\n",
        "random_choose_train_masks = np.array(masks_images)[b]\n",
        "\n",
        "fig = plt.figure(figsize=(15, 26))\n",
        "#fig.tight_layout()\n",
        "\n",
        "subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0.2, wspace = 0)\n",
        "\n",
        "columns = 2\n",
        "rows = SIZE_OF_RANDOM_CHOOSE\n",
        "ax = []\n",
        "\n",
        "for i in range(columns*rows):\n",
        "    if i % 2 == 0:\n",
        "      name = random_choose_test_file_names[i]\n",
        "      image = random_choose_train_images[i]\n",
        "      ax.append( fig.add_subplot(rows, columns, i+1) )\n",
        "      #ax[-1].set_title(\"ax:\"+str(i))  # set title\n",
        "      plt.imshow(image)\n",
        "      plt.title('{}.jpg'.format(name))\n",
        "    else:\n",
        "      name = random_choose_test_file_names[i-1]\n",
        "      image = random_choose_train_masks[i-1]\n",
        "      ax.append( fig.add_subplot(rows, columns, i+1) )\n",
        "      #ax[-1].set_title(\"ax:\"+str(i))  # set title\n",
        "      plt.imshow(1 - image)\n",
        "      plt.title('{}.jpg'.format(name))\n",
        "      \n",
        "\n",
        "#plt.subplots_adjust(wspace=0, hspace=0)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zgyc-rdIWugU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Теперь, когда мы изучили наш датасет, обсудим что такое задача сегментации и как её решать"
      ]
    },
    {
      "metadata": {
        "id": "DJP2FUm0bCNK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Задача бинарной сегментации: __  <img src=\" https://adeshpande3.github.io/assets/Segmentation2.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
      ]
    },
    {
      "metadata": {
        "id": "C9gpZQqTbCJS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Задача многоклассовой сегментации:__  <img src=\" https://neurohive.io/wp-content/uploads/2018/11/u-net-net.jpg\" alt=\"Drawing\" style=\"width: 700px;\"/> "
      ]
    },
    {
      "metadata": {
        "id": "uKl0iCclbCCj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Видео-демонстрация №1:__  \n",
        "<img src=\" https://thumbs.gfycat.com/RingedEveryBull-size_restricted.gif\" alt=\"Drawing\" style=\"width: 1000px;\"/> "
      ]
    },
    {
      "metadata": {
        "id": "GA4GkxAZbB9V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Видео-демонстрация №2:__\n",
        "\n",
        "<img src=\" https://thumbs.gfycat.com/DimSarcasticCockerspaniel-size_restricted.gif\" alt=\"Drawing\" style=\"width: 700px;\"/> "
      ]
    },
    {
      "metadata": {
        "id": "GF8eyf-3bB4C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Вопрос__: Что принимает на вход сеть, а что на выход? Для изображения размерностью (n, m, 3) какую размерность имеет target? Что содержится в target?"
      ]
    },
    {
      "metadata": {
        "id": "vzzz1d45eDB4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Вопрос__: Какая функция активации используется на последнем слое для 1) бинарной 2) многоклассовой классификации?"
      ]
    },
    {
      "metadata": {
        "id": "s0yPdl2a1ggV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Вопрос:__ Какую размерность имеет target в нашей заадче, если размерность каждого изображения (320, 240, 3)?"
      ]
    },
    {
      "metadata": {
        "id": "zDil20O6bByE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Примерная архитектура сети, которая позволяет решать такую задача:\n",
        "\n",
        "<img src=\"https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_7/Deconvnet.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
      ]
    },
    {
      "metadata": {
        "id": "Atl_CK7vlOHa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://cdn-images-1.medium.com/max/1600/1*LeETJKay90taXAD8dt3dhg.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n"
      ]
    },
    {
      "metadata": {
        "id": "cHe78B8PW2D3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Вопрос:__ Как будем делать Deconvolution network?"
      ]
    },
    {
      "metadata": {
        "id": "YBCW4BDMW1_e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Transposed Convolutions: (a.k.a. deconvolutions)"
      ]
    },
    {
      "metadata": {
        "id": "5A4D1uDwlkCW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\" https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_3/Conv_Deconv.PNG\" alt=\"Drawing\" style=\"width: 700px;\"/> "
      ]
    },
    {
      "metadata": {
        "id": "gO_RIPv2lkTx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\" https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_3/Deconv_exp.PNG\" alt=\"Drawing\" style=\"width: 700px;\"/> \n"
      ]
    },
    {
      "metadata": {
        "id": "BN0RVhZ2W16c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src=\" https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/no_padding_no_strides_transposed.gif\" alt=\"Drawing\" style=\"width: 700px;\"/> \n"
      ]
    },
    {
      "metadata": {
        "id": "O46EJf32W11i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Больше визуализаций: \n",
        "https://github.com/vdumoulin/conv_arithmetic"
      ]
    },
    {
      "metadata": {
        "id": "hjwugarNpaVQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Вопрос:__ А что насчет лосса? Как измерить схожесть двух target'ов?"
      ]
    },
    {
      "metadata": {
        "id": "jfvV48k5paP-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\\begin{align*} \n",
        "Dice(A,B) \n",
        "&= \\frac{2|A\\cdot B|}{ |A| + |B| } \\\\ \n",
        "F1(A,B) \n",
        "&= \\frac{2}{|A|/|A \\cdot B| + |B|/|A\\cdot B|} \\\\ \n",
        "Jaccard(A,B) \n",
        "&= \\frac{|A\\cdot B|}{|max(A,B)|} = \\frac{|A\\cdot B|}{|A|+|B|-|A\\cdot B|}\\\\ \n",
        "Accuracy(A,B)\n",
        "&= \\frac{|A\\cdot B|+|\\overline{A} \\cdot \\overline{B}|}{|All|} \\\\\n",
        "\\end{align*}"
      ]
    },
    {
      "metadata": {
        "id": "ZNyDqu8-mTcf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src=\" https://www.invicro.com/wp-content/uploads/2016/09/metrics.png\" alt=\"Drawing\" style=\"width: 700px;\"/> \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "-hHDGTy51kSi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Вопрос:__ Объясните логику, что считают коэффициенты Dice и Jaccard? "
      ]
    },
    {
      "metadata": {
        "id": "OJWV2hQZDIqn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Размерность images', images.shape)\n",
        "print('Размерность targeta:', masks.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kM5Tepow4N9Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_size_target = (320, 240)\n",
        "m = len(images)\n",
        "\n",
        "# Разделите все images и masks на train и test. 80% под тест\n",
        "# <YOUR CODE>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fizlmlET9Lbf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Нам нужно, чтобы train_masks имело 3 размерности\n",
        "\n",
        "# <YOUR CODE>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LaSL_VRw9qrZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Размерность train images', train_images.shape)\n",
        "print('Размерность test images', valid_images.shape)\n",
        "print('Размерность train targeta:', train_masks.shape)\n",
        "print('Размерность test targeta:', valid_masks.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jW0MCO6d496q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del masks, images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hvqi_KSO_MKp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Вопрос:__ Зачем мы удалили из памяти masks и images?"
      ]
    },
    {
      "metadata": {
        "id": "0Rdxeyn-_jgS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Опционально: аугментация данных:"
      ]
    },
    {
      "metadata": {
        "id": "LTb_YbhRwD6p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Сделайте аугментацию данных, а именно сделайте горизонтальный флип:\n",
        "# <YOUR CODE>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JCsi7pbe6b47",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Вопрос:__ После выполненной аугментации данных какова будет размерность обучающей выборки?"
      ]
    },
    {
      "metadata": {
        "id": "DVeUbfQ56c1E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(train_images.shape)\n",
        "print(train_masks.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "amzZIKIqpXFa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Объявляем метрики, которые нам вдальнейшем понадобятся:\n",
        "def dice_coef_np(y_true, y_pred, smooth=1):\n",
        "    intersection = (y_true.flatten() * y_pred.flatten()).sum()\n",
        "    return -(2. * intersection + smooth) / (y_true.sum() + y_pred.sum() + smooth)\n",
        "\n",
        "\n",
        "def dice_coef_batch(y_true_in, y_pred_in):\n",
        "    y_pred_in = (y_pred_in > 0.5).astype(np.float32)  # added by sgx 20180728\n",
        "    batch_size = y_true_in.shape[0]\n",
        "    metric = []\n",
        "    for batch in range(batch_size):\n",
        "        value = dice_coef_np(y_true_in[batch], y_pred_in[batch])\n",
        "        metric.append(value)\n",
        "    return np.mean(metric)\n",
        "\n",
        "\n",
        "def my_dice_metric(label, pred):\n",
        "    metric_value = tf.py_func(dice_coef_batch, [label, pred], tf.float64)\n",
        "    return metric_value\n",
        "\n",
        "\n",
        "def dice_coef_K(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_U3sR7D2v_Z4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2. Модель:"
      ]
    },
    {
      "metadata": {
        "id": "Gb_zsg4tC_XU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Baseline: Unet"
      ]
    },
    {
      "metadata": {
        "id": "8M_ujGq7C2T3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src=\" https://camo.githubusercontent.com/cf2ff198ddd4f4600726fa0f2844e77c4041186b/68747470733a2f2f686162726173746f726167652e6f72672f776562742f68752f6a692f69722f68756a696972767067706637657377713838685f783761686c69772e706e67\" alt=\"Drawing\" style=\"width: 700px;\"/> \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "fjhU4XoIk5kA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
        "    # first layer\n",
        "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
        "               padding=\"same\")(input_tensor)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    # second layer\n",
        "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
        "               padding=\"same\")(x)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wDktGBC3klrW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):\n",
        "    # contracting path\n",
        "    c1 = conv2d_block(input_img, n_filters=n_filters * 1, kernel_size=3, batchnorm=batchnorm)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    p1 = Dropout(dropout * 0.5)(p1)\n",
        "\n",
        "    c2 = conv2d_block(p1, n_filters=n_filters * 2, kernel_size=3, batchnorm=batchnorm)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "    p2 = Dropout(dropout)(p2)\n",
        "\n",
        "    c3 = conv2d_block(p2, n_filters=n_filters * 4, kernel_size=3, batchnorm=batchnorm)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "    p3 = Dropout(dropout)(p3)\n",
        "\n",
        "    c4 = conv2d_block(p3, n_filters=n_filters * 8, kernel_size=3, batchnorm=batchnorm)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "    p4 = Dropout(dropout)(p4)\n",
        "\n",
        "    c5 = conv2d_block(p4, n_filters=n_filters * 16, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    # expansive path\n",
        "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    u6 = Dropout(dropout)(u6)\n",
        "    c6 = conv2d_block(u6, n_filters=n_filters * 8, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    u7 = Dropout(dropout)(u7)\n",
        "    c7 = conv2d_block(u7, n_filters=n_filters * 4, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    u8 = Dropout(dropout)(u8)\n",
        "    c8 = conv2d_block(u8, n_filters=n_filters * 2, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    u9 = Dropout(dropout)(u9)\n",
        "    c9 = conv2d_block(u9, n_filters=n_filters * 1, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "    model = Model(inputs=[input_img], outputs=[outputs])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef_K])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E0_sFwQ1kws4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "load = True\n",
        "\n",
        "\n",
        "if load:\n",
        "    # Уже обученная модель:\n",
        "    model = load_model('models/unet_weights.49-val_loss0.12--0.96.hdf5.model', custom_objects={'dice_coef_K': dice_coef_K, 'my_dice_metric': my_dice_metric})\n",
        "    model.summary()\n",
        "else:\n",
        "    # Если обучать с нуля:\n",
        "    input_img = Input(img_size_target + (3,), name='img')\n",
        "    model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
        "    model.summary()\n",
        "\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\"models/unet_weights.{epoch:02d}-val_loss{val_loss:.2f}-{val_dice_coef_K:.2f}.hdf5.model\",\n",
        "                                   monitor='val_dice_coef_K', mode='min', save_best_only=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.2, patience=3, min_lr=0.00001, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YBcplprUwKpP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3. Обучение:"
      ]
    },
    {
      "metadata": {
        "id": "FHIqJ6NhkxXW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "batch_size = 16\n",
        "\n",
        "print(train_images.shape)\n",
        "print(train_masks.shape)\n",
        "print(valid_images.shape)\n",
        "print(valid_masks.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D_AujLkBliR9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(train_images, train_masks,\n",
        "                    validation_data=[[valid_images], [valid_masks]],\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[model_checkpoint, reduce_lr],\n",
        "                    verbose=1)\n",
        "print('Fitted!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fR4SpBbVwReM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 4. Другая модель с residual блоками:"
      ]
    },
    {
      "metadata": {
        "id": "xe385z0nTTyT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
        "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    if activation == True:\n",
        "        x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def residual_block(blockInput, num_filters=16):\n",
        "    x = Activation('relu')(blockInput)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = convolution_block(x, num_filters, (3,3) )\n",
        "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
        "    x = Add()([x, blockInput])\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "48Q2EVisTTuu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def build_model(input_layer, start_neurons, DropoutRatio=0.5):\n",
        "    # (320, 240) -> (160, 120)\n",
        "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n",
        "    conv1 = residual_block(conv1, start_neurons * 1)\n",
        "    conv1 = residual_block(conv1, start_neurons * 1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
        "    pool1 = Dropout(DropoutRatio / 2)(pool1)\n",
        "\n",
        "    # (160, 120) -> (80, 60)\n",
        "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
        "    conv2 = residual_block(conv2, start_neurons * 2)\n",
        "    conv2 = residual_block(conv2, start_neurons * 2)\n",
        "    conv2 = Activation('relu')(conv2)\n",
        "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "    pool2 = Dropout(DropoutRatio)(pool2)\n",
        "\n",
        "    # (80, 60) -> (40, 30)\n",
        "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
        "    conv3 = residual_block(conv3, start_neurons * 4)\n",
        "    conv3 = residual_block(conv3, start_neurons * 4)\n",
        "    conv3 = Activation('relu')(conv3)\n",
        "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
        "    pool3 = Dropout(DropoutRatio)(pool3)\n",
        "\n",
        "    # (40, 30) -> (20, 15)\n",
        "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
        "    conv4 = residual_block(conv4, start_neurons * 8)\n",
        "    conv4 = residual_block(conv4, start_neurons * 8)\n",
        "    conv4 = Activation('relu')(conv4)\n",
        "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
        "    pool4 = Dropout(DropoutRatio)(pool4)\n",
        "\n",
        "    # (20, 15) -> (10, 7)\n",
        "    conv5 = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n",
        "    conv5 = residual_block(conv5, start_neurons * 16)\n",
        "    conv5 = residual_block(conv5, start_neurons * 16)\n",
        "    conv5 = Activation('relu')(conv5)\n",
        "    pool5 = MaxPooling2D((2, 2))(conv5)\n",
        "    pool5 = Dropout(DropoutRatio)(pool5)\n",
        "\n",
        "    # Middle\n",
        "    convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool5)\n",
        "    convm = residual_block(convm, start_neurons * 32)\n",
        "    convm = residual_block(convm, start_neurons * 32)\n",
        "    convm = Activation('relu')(convm)\n",
        "\n",
        "    col = Reshape((20, 256, 15))(conv5)\n",
        "    col = Conv2D(1, 1, activation=None, padding='same')(col)\n",
        "    col = Flatten()(col)\n",
        "\n",
        "    # (20, 15) -> (40, 30)\n",
        "    deconv5 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\", use_bias=True)(convm)\n",
        "    deconv5 = Flatten()(deconv5)\n",
        "    deconv5 = concatenate([deconv5, col])\n",
        "    deconv5 = Reshape((20, 15, 256))(deconv5)\n",
        "    uconv5 = concatenate([deconv5, conv5])\n",
        "    uconv5 = Dropout(DropoutRatio)(uconv5)\n",
        "\n",
        "    uconv5 = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv5)\n",
        "    uconv5 = residual_block(uconv5, start_neurons * 16)\n",
        "    uconv5 = residual_block(uconv5, start_neurons * 16)\n",
        "    uconv5 = Activation('relu')(uconv5)\n",
        "\n",
        "    # (20, 15) -> (40, 30)\n",
        "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv5)\n",
        "    uconv4 = concatenate([deconv4, conv4])\n",
        "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
        "\n",
        "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
        "    uconv4 = residual_block(uconv4, start_neurons * 8)\n",
        "    uconv4 = residual_block(uconv4, start_neurons * 8)\n",
        "    uconv4 = Activation('relu')(uconv4)\n",
        "\n",
        "    # 12 -> 25\n",
        "    # deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
        "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
        "    uconv3 = concatenate([deconv3, conv3])\n",
        "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
        "\n",
        "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
        "    uconv3 = residual_block(uconv3, start_neurons * 4)\n",
        "    uconv3 = residual_block(uconv3, start_neurons * 4)\n",
        "    uconv3 = Activation('relu')(uconv3)\n",
        "\n",
        "    # 25 -> 50\n",
        "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
        "    uconv2 = concatenate([deconv2, conv2])\n",
        "\n",
        "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
        "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
        "    uconv2 = residual_block(uconv2, start_neurons * 2)\n",
        "    uconv2 = residual_block(uconv2, start_neurons * 2)\n",
        "    uconv2 = Activation('relu')(uconv2)\n",
        "\n",
        "    # 50 -> 101\n",
        "    # deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
        "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
        "    uconv1 = concatenate([deconv1, conv1])\n",
        "\n",
        "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
        "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
        "    uconv1 = residual_block(uconv1, start_neurons * 1)\n",
        "    uconv1 = residual_block(uconv1, start_neurons * 1)\n",
        "    uconv1 = Activation('relu')(uconv1)\n",
        "\n",
        "    uconv1 = Dropout(DropoutRatio / 2)(uconv1)\n",
        "    output_layer = Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
        "\n",
        "    return output_layer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B7kJ7bF8O8az",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Объявление модели: \n",
        "input_layer = Input(img_size_target + (3,))\n",
        "output_layer = build_model(input_layer, 16, 0.5)\n",
        "model = Model(input_layer, output_layer)\n",
        "model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=[my_dice_metric])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pt7Z8dtkwcId",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 5. Предсказание:"
      ]
    },
    {
      "metadata": {
        "id": "cNPji5E3O8W4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del train_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "di__4dP-sFww",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict_result(model ,x_test ,img_size_target): # predict both orginal and reflect x\n",
        "    #x_test_reflect = np.array([np.fliplr(x) for x in x_test])\n",
        "    #x_test_reflect = x_test_reflect\n",
        "    print('Predicting...')\n",
        "    preds_test1 = model.predict(x_test, verbose=1)  # .reshape(-1, img_size_target[0], img_size_target[1])\n",
        "    # preds_test2_refect = model.predict(x_test_reflect).reshape(-1, img_size_target[0], img_size_target[1])\n",
        "    # preds_test2 = np.array([ np.fliplr(x) for x in preds_test2_refect] )\n",
        "    # preds_avg = (preds_test1 + preds_test2)/2\n",
        "    # return preds_avg\n",
        "    return preds_test1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TYXawqvqwfeM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Считаем данные из папки test и сделаем для них предсказание:"
      ]
    },
    {
      "metadata": {
        "id": "jil2RTO4sFux",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_dir = 'data/test/'\n",
        "test_images = np.array([np.array(load_img(join(test_dir, f), grayscale=False)) / 255\n",
        "                        for f in listdir(test_dir) if isfile(join(test_dir, f))])\n",
        "test_file_names = [f[:f.find('.')] for f in listdir(test_dir) if isfile(join(test_dir, f))]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bt8_4uissFss",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# будем предсказывать не для всех фотографий (их слишком много), а случаайно выбранные n фотографий\n",
        "RANDOM_CHOOSE_FOR_PREDICT = 7\n",
        "# Рандомно выберите RANDOM_CHOOSE_FOR_PREDICT изображений:\n",
        "temp_ = # YOUR CODE\n",
        "valid_images = test_images[temp_]\n",
        "\n",
        "pred_masks = predict_result(model, valid_images, img_size_target)\n",
        "for i, mask in enumerate(pred_masks):\n",
        "    # Сохраняем исходное фото:\n",
        "    initial_im = Image.fromarray((valid_images[i] * 255).astype(np.uint8))\n",
        "    initial_im.save(\"output_reduced/test_output/{}_initial.png\".format(test_file_names[i]))\n",
        "\n",
        "    # Сохраняем маску:\n",
        "    pred_mask = (pred_masks[i]).reshape((320, 240))\n",
        "    pred_mask = np.round(pred_mask) * 255\n",
        "    pred_mask = pred_mask.astype(np.uint8)\n",
        "    new_p = Image.fromarray(pred_mask)\n",
        "    new_p.save(\"output_reduced/test_output/{}_mask.png\".format(test_file_names[i]))\n",
        "    \n",
        "    # Наложим маску и фото и сохраним:\n",
        "    val_image = valid_images[i].copy()\n",
        "    val_image = np.round(val_image * 255, 0).astype(np.uint8)\n",
        "\n",
        "    # Возможно, это особенности работы функций opencv. В этом пакете кодировка BGR вместо RGB\n",
        "    val_image = np.concatenate([val_image[:, :, 2].reshape(val_image.shape[:2] + (1,)),\n",
        "                                val_image[:, :, 1].reshape(val_image.shape[:2] + (1,)),\n",
        "                                val_image[:, :, 0].reshape(val_image.shape[:2] + (1,))], axis=2)\n",
        "    pred_mask_red = np.zeros(pred_mask.shape + (3,), np.uint8)\n",
        "    pred_mask_red[:, :, 2] = pred_mask.copy()\n",
        "    blended_image = cv2.addWeighted(pred_mask_red, 1, val_image, 1, 0)\n",
        "    cv2.imwrite('output_reduced/test_output/{}_image_plus_mask.png'.format(test_file_names[i]), blended_image)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jDCLFKlbxQ_Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 6. Визуализация:"
      ]
    },
    {
      "metadata": {
        "id": "inAqx-REsVJT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SIZE_OF_RANDOM_CHOOSE = 7\n",
        "# Считыавем предсказанные маски:\n",
        "pred_masks_dir = 'output_reduced/test_output'\n",
        "pred_masks = np.array([np.array(load_img(join(pred_masks_dir, f), grayscale=False)) / 255\n",
        "                        for f in listdir(pred_masks_dir) if isfile(join(pred_masks_dir, f))])\n",
        "pred_masks_names = [f[:f.find('.')] for f in listdir(pred_masks_dir) if isfile(join(pred_masks_dir, f))]\n",
        "pred_masks_names, pred_masks = zip(*sorted(zip(pred_masks_names, pred_masks)))\n",
        "\n",
        "# Выбираем рандомно несколько изображений:\n",
        "temp_ = np.array(list(range(0, len(pred_masks_names)))).reshape((-1, 3))\n",
        "b = temp_[np.random.choice(temp_.shape[0], SIZE_OF_RANDOM_CHOOSE, replace=False), :].flatten()\n",
        "random_choose_pred_masks_names = np.array(pred_masks_names)[b]\n",
        "random_choose_pred_masks = np.array(pred_masks)[b]\n",
        "\n",
        "fig = plt.figure(figsize=(15, 26))\n",
        "subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0.2, wspace = 0)\n",
        "columns = 3\n",
        "rows = SIZE_OF_RANDOM_CHOOSE\n",
        "ax = []\n",
        "\n",
        "for i in range(columns*rows):\n",
        "    name = random_choose_pred_masks_names[i]\n",
        "    image = random_choose_pred_masks[i]\n",
        "    ax.append( fig.add_subplot(rows, columns, i+1) )\n",
        "    #ax[-1].set_title(\"ax:\"+str(i))  # set title\n",
        "    plt.imshow(image)\n",
        "    plt.title('{}.jpg'.format(name))\n",
        "\n",
        "#plt.subplots_adjust(wspace=0, hspace=0)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A9JziHvcLvvq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 7. Сравнение двух моделей:"
      ]
    },
    {
      "metadata": {
        "id": "DZFCPPzKKOq1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1 = load_model('models/unet_weights.49-val_loss0.12--0.96.hdf5.model', custom_objects={'dice_coef_K': dice_coef_K, 'my_dice_metric': my_dice_metric})\n",
        "model2 = load_model('models/resnet_weights.17--0.95.hdf5.model', custom_objects={'dice_coef_K': dice_coef_K, 'my_dice_metric': my_dice_metric})\n",
        "!mkdir output_reduced/new_test_output_unet\n",
        "!mkdir output_reduced/new_test_output_resnet_unet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N1G2FjWvLZqx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_dir = 'data/new_test/'\n",
        "test_images = np.array([np.array(load_img(join(test_dir, f), grayscale=False)) / 255\n",
        "                        for f in listdir(test_dir) if (isfile(join(test_dir, f)) and f != '.DS_Store')])\n",
        "test_file_names = [f[:f.find('.')] for f in listdir(test_dir) if isfile(join(test_dir, f))]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FDH6LaeLLZnG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# будем предсказывать не для всех фотографий (их слишком много), а случаайно выбранные n фотографий\n",
        "RANDOM_CHOOSE_FOR_PREDICT = 7\n",
        "# Рандомно выберите RANDOM_CHOOSE_FOR_PREDICT изображений:\n",
        "valid_images = test_images\n",
        "\n",
        "pred_masks = predict_result(model1, valid_images, img_size_target)\n",
        "for i, mask in enumerate(pred_masks):\n",
        "    # Сохраняем исходное фото:\n",
        "    initial_im = Image.fromarray((valid_images[i] * 255).astype(np.uint8))\n",
        "    initial_im.save(\"output_reduced/new_test_output_unet/{}_initial.png\".format(test_file_names[i]))\n",
        "\n",
        "    # Сохраняем маску:\n",
        "    pred_mask = (pred_masks[i]).reshape((320, 240))\n",
        "    pred_mask = np.round(pred_mask) * 255\n",
        "    pred_mask = pred_mask.astype(np.uint8)\n",
        "    new_p = Image.fromarray(pred_mask)\n",
        "    new_p.save(\"output_reduced/new_test_output_unet/{}_mask.png\".format(test_file_names[i]))\n",
        "    \n",
        "    # Наложим маску и фото и сохраним:\n",
        "    val_image = valid_images[i].copy()\n",
        "    val_image = np.round(val_image * 255, 0).astype(np.uint8)\n",
        "\n",
        "    # Возможно, это особенности работы функций opencv. В этом пакете кодировка BGR вместо RGB\n",
        "    val_image = np.concatenate([val_image[:, :, 2].reshape(val_image.shape[:2] + (1,)),\n",
        "                                val_image[:, :, 1].reshape(val_image.shape[:2] + (1,)),\n",
        "                                val_image[:, :, 0].reshape(val_image.shape[:2] + (1,))], axis=2)\n",
        "    pred_mask_red = np.zeros(pred_mask.shape + (3,), np.uint8)\n",
        "    pred_mask_red[:, :, 2] = pred_mask.copy()\n",
        "    blended_image = cv2.addWeighted(pred_mask_red, 1, val_image, 1, 0)\n",
        "    cv2.imwrite('output_reduced/new_test_output_unet/{}_image_plus_mask.png'.format(test_file_names[i]), blended_image)\n",
        "\n",
        "pred_masks = predict_result(model2, valid_images, img_size_target)\n",
        "for i, mask in enumerate(pred_masks):\n",
        "    # Сохраняем исходное фото:\n",
        "    initial_im = Image.fromarray((valid_images[i] * 255).astype(np.uint8))\n",
        "    initial_im.save(\"output_reduced/new_test_output_resnet_unet/{}_initial.png\".format(test_file_names[i]))\n",
        "\n",
        "    # Сохраняем маску:\n",
        "    pred_mask = (pred_masks[i]).reshape((320, 240))\n",
        "    pred_mask = np.round(pred_mask) * 255\n",
        "    pred_mask = pred_mask.astype(np.uint8)\n",
        "    new_p = Image.fromarray(pred_mask)\n",
        "    new_p.save(\"output_reduced/new_test_output_resnet_unet/{}_mask.png\".format(test_file_names[i]))\n",
        "    \n",
        "    # Наложим маску и фото и сохраним:\n",
        "    val_image = valid_images[i].copy()\n",
        "    val_image = np.round(val_image * 255, 0).astype(np.uint8)\n",
        "\n",
        "    # Возможно, это особенности работы функций opencv. В этом пакете кодировка BGR вместо RGB\n",
        "    val_image = np.concatenate([val_image[:, :, 2].reshape(val_image.shape[:2] + (1,)),\n",
        "                                val_image[:, :, 1].reshape(val_image.shape[:2] + (1,)),\n",
        "                                val_image[:, :, 0].reshape(val_image.shape[:2] + (1,))], axis=2)\n",
        "    pred_mask_red = np.zeros(pred_mask.shape + (3,), np.uint8)\n",
        "    pred_mask_red[:, :, 2] = pred_mask.copy()\n",
        "    blended_image = cv2.addWeighted(pred_mask_red, 1, val_image, 1, 0)\n",
        "    cv2.imwrite('output_reduced/new_test_output_resnet_unet/{}_image_plus_mask.png'.format(test_file_names[i]), blended_image)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rIz3r6OtLZjA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Считыавем предсказанные маски:\n",
        "pred_masks_dir = 'output_reduced/new_test_output_unet'\n",
        "pred_masks = np.array([np.array(load_img(join(pred_masks_dir, f), grayscale=False)) / 255\n",
        "                        for f in listdir(pred_masks_dir) if isfile(join(pred_masks_dir, f))])\n",
        "pred_masks_names = [f[:f.find('.')] for f in listdir(pred_masks_dir) if isfile(join(pred_masks_dir, f))]\n",
        "pred_masks_names, pred_masks = zip(*sorted(zip(pred_masks_names, pred_masks)))\n",
        "\n",
        "\n",
        "random_choose_pred_masks_names = np.array(pred_masks_names)\n",
        "random_choose_pred_masks = np.array(pred_masks)\n",
        "\n",
        "fig = plt.figure(figsize=(15, 26))\n",
        "subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0.2, wspace = 0)\n",
        "columns = 3\n",
        "rows = SIZE_OF_RANDOM_CHOOSE\n",
        "ax = []\n",
        "\n",
        "for i in range(columns*rows):\n",
        "    name = random_choose_pred_masks_names[i]\n",
        "    image = random_choose_pred_masks[i]\n",
        "    ax.append( fig.add_subplot(rows, columns, i+1) )\n",
        "    #ax[-1].set_title(\"ax:\"+str(i))  # set title\n",
        "    plt.imshow(image)\n",
        "    plt.title('{}.jpg'.format(name))\n",
        "\n",
        "#plt.subplots_adjust(wspace=0, hspace=0)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sqpPGEe6LZfJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Считыавем предсказанные маски:\n",
        "pred_masks_dir = 'output_reduced/new_test_output_resnet_unet'\n",
        "pred_masks = np.array([np.array(load_img(join(pred_masks_dir, f), grayscale=False)) / 255\n",
        "                        for f in listdir(pred_masks_dir) if isfile(join(pred_masks_dir, f))])\n",
        "pred_masks_names = [f[:f.find('.')] for f in listdir(pred_masks_dir) if isfile(join(pred_masks_dir, f))]\n",
        "pred_masks_names, pred_masks = zip(*sorted(zip(pred_masks_names, pred_masks)))\n",
        "\n",
        "\n",
        "random_choose_pred_masks_names = np.array(pred_masks_names)\n",
        "random_choose_pred_masks = np.array(pred_masks)\n",
        "\n",
        "fig = plt.figure(figsize=(15, 26))\n",
        "subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0.2, wspace = 0)\n",
        "columns = 3\n",
        "rows = SIZE_OF_RANDOM_CHOOSE\n",
        "ax = []\n",
        "\n",
        "for i in range(columns*rows):\n",
        "    name = random_choose_pred_masks_names[i]\n",
        "    image = random_choose_pred_masks[i]\n",
        "    ax.append( fig.add_subplot(rows, columns, i+1) )\n",
        "    #ax[-1].set_title(\"ax:\"+str(i))  # set title\n",
        "    plt.imshow(image)\n",
        "    plt.title('{}.jpg'.format(name))\n",
        "\n",
        "#plt.subplots_adjust(wspace=0, hspace=0)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MMzaY2sdyVIt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 8. Бонус:"
      ]
    },
    {
      "metadata": {
        "id": "hJj5lvyQsslw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Можно подгрузить произвольную фотографию в папку data/try_prediction"
      ]
    },
    {
      "metadata": {
        "id": "EDUIBbKlsrN4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_dir = 'data/try_prediction/'\n",
        "test_images = np.array([np.array(load_img(join(test_dir, f), grayscale=False)) / 255\n",
        "                        for f in listdir(test_dir) if isfile(join(test_dir, f))])\n",
        "test_file_names = [f[:f.find('.')] for f in listdir(test_dir) if isfile(join(test_dir, f))]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sQthSU2DxCVZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "im=(Image.open('data/try_prediction/1.jpg'))\n",
        "im = im.resize((240, 320), Image.ANTIALIAS)\n",
        "imgArr = np.array(im).reshape((1, 320, 240, 3)) / 255\n",
        "\n",
        "plt.imshow(imgArr[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DKPrR0WRsrIW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_images = imgArr\n",
        "\n",
        "pred_masks = predict_result(model, valid_images, img_size_target)\n",
        "# save initial image\n",
        "for i, mask in enumerate(pred_masks):\n",
        "    # Initial image\n",
        "    initial_im = Image.fromarray((valid_images[i] * 255).astype(np.uint8))\n",
        "    initial_im.save(\"output_reduced/output_try_prediction/{}_initial.png\".format(test_file_names[i]))\n",
        "\n",
        "    # Mask\n",
        "    pred_mask = (pred_masks[i]).reshape((320, 240))\n",
        "    pred_mask = np.round(pred_mask) * 255\n",
        "    pred_mask = pred_mask.astype(np.uint8)\n",
        "    # try_one_image = try_one_image.reshape((try_one_image.shape[0], try_one_image.shape[1], 1))\n",
        "    new_p = Image.fromarray(pred_mask)\n",
        "    new_p.save(\"output_reduced/output_try_prediction/{}_mask.png\".format(test_file_names[i]))\n",
        "\n",
        "    val_image = valid_images[i].copy()\n",
        "    val_image = np.round(val_image * 255, 0).astype(np.uint8)\n",
        "\n",
        "    # Возможно, это особенности работы функций opencv. В этом пакете кодировка BGR вместо RGB\n",
        "    val_image = np.concatenate([val_image[:, :, 2].reshape(val_image.shape[:2] + (1,)),\n",
        "                                val_image[:, :, 1].reshape(val_image.shape[:2] + (1,)),\n",
        "                                val_image[:, :, 0].reshape(val_image.shape[:2] + (1,))], axis=2)\n",
        "    pred_mask_red = np.zeros(pred_mask.shape + (3,), np.uint8)\n",
        "    pred_mask_red[:, :, 2] = pred_mask.copy()\n",
        "    blended_image = cv2.addWeighted(pred_mask_red, 1, val_image, 1, 0)\n",
        "    cv2.imwrite('output_reduced/output_try_prediction/{}_image_plus_mask.png'.format(test_file_names[i]), blended_image)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sfiynRCcsrFQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#SIZE_OF_RANDOM_CHOOSE = 7\n",
        "# Считыавем тестовые изображения:\n",
        "pred_masks_dir = 'output_reduced/output_try_prediction'\n",
        "pred_masks = np.array([np.array(load_img(join(pred_masks_dir, f), grayscale=False)) / 255\n",
        "                        for f in listdir(pred_masks_dir) if isfile(join(pred_masks_dir, f))])\n",
        "pred_masks_names = [f[:f.find('.')] for f in listdir(pred_masks_dir) if isfile(join(pred_masks_dir, f))]\n",
        "pred_masks_names, pred_masks = zip(*sorted(zip(pred_masks_names, pred_masks)))\n",
        "\n",
        "\n",
        "random_choose_pred_masks_names = np.array(pred_masks_names)\n",
        "random_choose_pred_masks = np.array(pred_masks)\n",
        "\n",
        "fig = plt.figure(figsize=(15, 26))\n",
        "#fig.tight_layout()\n",
        "\n",
        "subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0.1, wspace = 0)\n",
        "\n",
        "columns = 3\n",
        "rows = len(pred_masks_names) // 3\n",
        "ax = []\n",
        "\n",
        "for i in range(columns*rows):\n",
        "    name = random_choose_pred_masks_names[i]\n",
        "    image = random_choose_pred_masks[i]\n",
        "    ax.append( fig.add_subplot(rows, columns, i+1) )\n",
        "    #ax[-1].set_title(\"ax:\"+str(i))  # set title\n",
        "    plt.imshow(image)\n",
        "\n",
        "#plt.subplots_adjust(wspace=0, hspace=0)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ilMlxhw7KAow",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Бонус 2: функция, возвращающая все переменные и их размер"
      ]
    },
    {
      "metadata": {
        "id": "97J4wiZcsFn9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "def sizeof_fmt(num, suffix='B'):\n",
        "    ''' By Fred Cirera, after https://stackoverflow.com/a/1094933/1870254'''\n",
        "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
        "        if abs(num) < 1024.0:\n",
        "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
        "        num /= 1024.0\n",
        "    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
        "\n",
        "for name, size in sorted(((name, sys.getsizeof(value)) for name,value in locals().items()),\n",
        "                         key= lambda x: -x[1])[:10]:\n",
        "    print(\"{:>30}: {:>8}\".format(name,sizeof_fmt(size)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}