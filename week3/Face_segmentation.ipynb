{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_notebook (2).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "DarZnvmuOiac"
      },
      "cell_type": "markdown",
      "source": [
        "## Сегментация. Выделение человека по фотографии"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "W6eewEO7TXUR"
      },
      "cell_type": "markdown",
      "source": [
        "1. Датасет: фотографии человека. Target - маска пикселей, где есть человек, а где нет"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "7zyay1nHL93c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "c24e4dc9-437c-4c76-f3bf-d6bbcc67e418"
      },
      "cell_type": "code",
      "source": [
        "# Сначала сделаем загрузку данных:\n",
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/DmitriiDenisov/intro_dl_seminars/master/setup_colab.py -O setup_google_colab.py\n",
        "from setup_google_colab import setup_week3\n",
        "setup_week3()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-20 19:06:22--  https://raw.githubusercontent.com/DmitriiDenisov/intro_dl_seminars/master/setup_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1109 (1.1K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "\rsetup_google_colab.   0%[                    ]       0  --.-KB/s               \rsetup_google_colab. 100%[===================>]   1.08K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-20 19:06:22 (141 MB/s) - ‘setup_google_colab.py’ saved [1109/1109]\n",
            "\n",
            "week3\n",
            "/content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "data.zip: 100%|██████████| 302M/302M [00:08<00:00, 34.0MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "22LSL6XQgTdb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5876d467-30e3-4057-ab43-a6e27de454df"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import numpy as np\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dropout, BatchNormalization, Activation, Add, Flatten, Dense, Reshape, UpSampling2D\n",
        "from keras.layers.core import Lambda\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img#,save_img\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "RF9jxXkXgmQa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "25c61091-6967-4ea4-d0eb-44f54c54cd29"
      },
      "cell_type": "code",
      "source": [
        "# Set some parameters\n",
        "im_width = 101\n",
        "im_height = 101\n",
        "im_chan = 1\n",
        "img_size_ori = (320, 240)\n",
        "img_size_target = (320, 240)\n",
        "\n",
        "train_dir = 'data/train/'\n",
        "images = [np.array(load_img(join(train_dir, f), grayscale=False)) / 255\n",
        "                for f in listdir(train_dir) if isfile(join(train_dir, f))]\n",
        "masks_dir = 'data/train_mask/'\n",
        "masks = [np.array(load_img(join(masks_dir, f), grayscale=True)) / 255\n",
        "               for f in listdir(masks_dir) if isfile(join(masks_dir, f))]\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py:98: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "UGEw7wK8gqkX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create train/validation split stratified by salt coverage\n",
        "m = len(images)\n",
        "train_obs = np.random.choice(range(m), size=round(0.8 * m), replace=False)\n",
        "valid_obs = np.delete(range(m), train_obs)\n",
        "\n",
        "train_images = np.array([images[i] for i in train_obs])\n",
        "train_masks = np.array([masks[i].reshape(img_size_target + (1,)) for i in train_obs])\n",
        "valid_images = np.array([images[i] for i in valid_obs])\n",
        "valid_masks = np.array([masks[i].reshape(img_size_target + (1,)) for i in valid_obs])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "amzZIKIqpXFa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dice_coef_K(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return -(2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_DA55qaFkdxJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
        "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    if activation == True:\n",
        "        x = Activation('relu')(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tSKKXyB1kg8y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def residual_block(blockInput, num_filters=16):\n",
        "    x = Activation('relu')(blockInput)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = convolution_block(x, num_filters, (3,3) )\n",
        "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
        "    x = Add()([x, blockInput])\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x2FK8ualkipc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def build_model(input_layer, start_neurons, DropoutRatio=0.5):\n",
        "    # (320, 240) -> (160, 120)\n",
        "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n",
        "    conv1 = residual_block(conv1, start_neurons * 1)\n",
        "    conv1 = residual_block(conv1, start_neurons * 1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
        "    pool1 = Dropout(DropoutRatio / 2)(pool1)\n",
        "\n",
        "    # (160, 120) -> (80, 60)\n",
        "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
        "    conv2 = residual_block(conv2, start_neurons * 2)\n",
        "    conv2 = residual_block(conv2, start_neurons * 2)\n",
        "    conv2 = Activation('relu')(conv2)\n",
        "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "    pool2 = Dropout(DropoutRatio)(pool2)\n",
        "\n",
        "    # (80, 60) -> (40, 30)\n",
        "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
        "    conv3 = residual_block(conv3, start_neurons * 4)\n",
        "    conv3 = residual_block(conv3, start_neurons * 4)\n",
        "    conv3 = Activation('relu')(conv3)\n",
        "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
        "    pool3 = Dropout(DropoutRatio)(pool3)\n",
        "\n",
        "    # (40, 30) -> (20, 15)\n",
        "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
        "    conv4 = residual_block(conv4, start_neurons * 8)\n",
        "    conv4 = residual_block(conv4, start_neurons * 8)\n",
        "    conv4 = Activation('relu')(conv4)\n",
        "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
        "    pool4 = Dropout(DropoutRatio)(pool4)\n",
        "\n",
        "    # (20, 15) -> (10, 7)\n",
        "    conv5 = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n",
        "    conv5 = residual_block(conv5, start_neurons * 16)\n",
        "    conv5 = residual_block(conv5, start_neurons * 16)\n",
        "    conv5 = Activation('relu')(conv5)\n",
        "    pool5 = MaxPooling2D((2, 2))(conv5)\n",
        "    pool5 = Dropout(DropoutRatio)(pool5)\n",
        "\n",
        "    # Middle\n",
        "    convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool5)\n",
        "    convm = residual_block(convm, start_neurons * 32)\n",
        "    convm = residual_block(convm, start_neurons * 32)\n",
        "    convm = Activation('relu')(convm)\n",
        "\n",
        "    col = Reshape((20, 256, 15))(conv5)\n",
        "    col = Conv2D(1, 1, activation=None, padding='same')(col)\n",
        "    col = Flatten()(col)\n",
        "\n",
        "    # (20, 15) -> (40, 30)\n",
        "    deconv5 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\", use_bias=True)(convm)\n",
        "    deconv5 = Flatten()(deconv5)\n",
        "    deconv5 = concatenate([deconv5, col])\n",
        "    deconv5 = Reshape((20, 15, 256))(deconv5)\n",
        "    uconv5 = concatenate([deconv5, conv5])\n",
        "    uconv5 = Dropout(DropoutRatio)(uconv5)\n",
        "\n",
        "    uconv5 = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv5)\n",
        "    uconv5 = residual_block(uconv5, start_neurons * 16)\n",
        "    uconv5 = residual_block(uconv5, start_neurons * 16)\n",
        "    uconv5 = Activation('relu')(uconv5)\n",
        "\n",
        "    # (20, 15) -> (40, 30)\n",
        "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv5)\n",
        "    uconv4 = concatenate([deconv4, conv4])\n",
        "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
        "\n",
        "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
        "    uconv4 = residual_block(uconv4, start_neurons * 8)\n",
        "    uconv4 = residual_block(uconv4, start_neurons * 8)\n",
        "    uconv4 = Activation('relu')(uconv4)\n",
        "\n",
        "    # 12 -> 25\n",
        "    # deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
        "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
        "    uconv3 = concatenate([deconv3, conv3])\n",
        "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
        "\n",
        "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
        "    uconv3 = residual_block(uconv3, start_neurons * 4)\n",
        "    uconv3 = residual_block(uconv3, start_neurons * 4)\n",
        "    uconv3 = Activation('relu')(uconv3)\n",
        "\n",
        "    # 25 -> 50\n",
        "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
        "    uconv2 = concatenate([deconv2, conv2])\n",
        "\n",
        "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
        "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
        "    uconv2 = residual_block(uconv2, start_neurons * 2)\n",
        "    uconv2 = residual_block(uconv2, start_neurons * 2)\n",
        "    uconv2 = Activation('relu')(uconv2)\n",
        "\n",
        "    # 50 -> 101\n",
        "    # deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
        "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
        "    uconv1 = concatenate([deconv1, conv1])\n",
        "\n",
        "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
        "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
        "    uconv1 = residual_block(uconv1, start_neurons * 1)\n",
        "    uconv1 = residual_block(uconv1, start_neurons * 1)\n",
        "    uconv1 = Activation('relu')(uconv1)\n",
        "\n",
        "    uconv1 = Dropout(DropoutRatio / 2)(uconv1)\n",
        "    output_layer = Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
        "\n",
        "    return output_layer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fjhU4XoIk5kA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
        "    # first layer\n",
        "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
        "               padding=\"same\")(input_tensor)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    # second layer\n",
        "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
        "               padding=\"same\")(x)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wDktGBC3klrW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):\n",
        "    # contracting path\n",
        "    c1 = conv2d_block(input_img, n_filters=n_filters * 1, kernel_size=3, batchnorm=batchnorm)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    p1 = Dropout(dropout * 0.5)(p1)\n",
        "\n",
        "    c2 = conv2d_block(p1, n_filters=n_filters * 2, kernel_size=3, batchnorm=batchnorm)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "    p2 = Dropout(dropout)(p2)\n",
        "\n",
        "    c3 = conv2d_block(p2, n_filters=n_filters * 4, kernel_size=3, batchnorm=batchnorm)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "    p3 = Dropout(dropout)(p3)\n",
        "\n",
        "    c4 = conv2d_block(p3, n_filters=n_filters * 8, kernel_size=3, batchnorm=batchnorm)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "    p4 = Dropout(dropout)(p4)\n",
        "\n",
        "    c5 = conv2d_block(p4, n_filters=n_filters * 16, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    # expansive path\n",
        "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    u6 = Dropout(dropout)(u6)\n",
        "    c6 = conv2d_block(u6, n_filters=n_filters * 8, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    u7 = Dropout(dropout)(u7)\n",
        "    c7 = conv2d_block(u7, n_filters=n_filters * 4, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    u8 = Dropout(dropout)(u8)\n",
        "    c8 = conv2d_block(u8, n_filters=n_filters * 2, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    u9 = Dropout(dropout)(u9)\n",
        "    c9 = conv2d_block(u9, n_filters=n_filters * 1, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "    model = Model(inputs=[input_img], outputs=[outputs])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef_K])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "niwFu7qLmkbY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "c95efa21-9455-45cf-926e-a30709410bea"
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "def sizeof_fmt(num, suffix='B'):\n",
        "    ''' By Fred Cirera, after https://stackoverflow.com/a/1094933/1870254'''\n",
        "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
        "        if abs(num) < 1024.0:\n",
        "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
        "        num /= 1024.0\n",
        "    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
        "\n",
        "for name, size in sorted(((name, sys.getsizeof(value)) for name,value in locals().items()),\n",
        "                         key= lambda x: -x[1])[:10]:\n",
        "    print(\"{:>30}: {:>8}\".format(name,sizeof_fmt(size)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  train_images:   2.0GiB\n",
            "                   train_masks: 699.0MiB\n",
            "                  valid_images: 523.8MiB\n",
            "                   valid_masks: 174.6MiB\n",
            "                        images:  12.7KiB\n",
            "                         masks:  12.7KiB\n",
            "                     train_obs:   9.4KiB\n",
            "                          _iii:   4.8KiB\n",
            "                           _i6:   4.8KiB\n",
            "                     valid_obs:   2.4KiB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E0_sFwQ1kws4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f0ab4945-7bac-4c2c-e306-ce64c39447cf"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Data augmentation\n",
        "# train_images = np.append(train_images, [np.fliplr(x) for x in train_images], axis=0)\n",
        "#del train_images\n",
        "\n",
        "\n",
        "# train_masks = np.append(train_masks, [np.fliplr(x) for x in train_masks], axis=0)\n",
        "#del train_masks\n",
        "\n",
        "# x_train2 = train_images\n",
        "# y_train2 = train_masks\n",
        "\n",
        "# sample = np.random.choice(range(x_train2.shape[0]), size=1000, replace=False)\n",
        "# x_train2 = np.array([x_train2[i, :, :, :] for i in sample])\n",
        "# y_train2 = np.array([y_train2[i, :, :, :] for i in sample])\n",
        "\n",
        "\n",
        "\n",
        "print(train_images.shape)\n",
        "print(train_masks.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1193, 320, 240, 3)\n",
            "(1193, 320, 240, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pEMJPoVRkxUd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ЯРОСЛАВ\n",
        "#input_layer = Input(img_size_target + (3,))\n",
        "#output_layer = build_model(input_layer, 16, 0.5)\n",
        "#model = Model(input_layer, output_layer)\n",
        "#model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=[my_dice_metric])\n",
        "#model.summary()\n",
        "\n",
        "#model = unet(input_size=img_size_target + (3,))\n",
        "# model = unet2(inputs=img_size_target + (3, ))\n",
        "# model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5PdJ0RsxkxZh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2755
        },
        "outputId": "66719b0c-fac8-43ba-c692-274c1023c78b"
      },
      "cell_type": "code",
      "source": [
        "load = True\n",
        "\n",
        "if load:\n",
        "    model = load_model('models/unet_weights.49-val_loss0.12--0.96.hdf5.model', custom_objects={'dice_coef_K': dice_coef_K})\n",
        "    model.summary()\n",
        "else:\n",
        "    input_img = Input(img_size_target + (3,), name='img')\n",
        "    model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
        "    model.summary()\n",
        "\n",
        "\n",
        "# early_stopping = EarlyStopping(monitor='val_my_dice_metric', mode = 'max',patience=20, verbose=1)\n",
        "model_checkpoint = ModelCheckpoint(\"../models/unet_weights.{epoch:02d}-val_loss{val_loss:.2f}-{val_dice_coef_K:.2f}.hdf5.model\",\n",
        "                                   monitor='val_dice_coef_K', mode='min', save_best_only=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.2, patience=3, min_lr=0.00001, verbose=1)\n",
        "#reduce_lr = ReduceLROnPlateau(factor=0.2, patience=5, min_lr=0.00001, verbose=1)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "img (InputLayer)                (None, 320, 240, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 320, 240, 16) 448         img[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 320, 240, 16) 64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 320, 240, 16) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 320, 240, 16) 2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 320, 240, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 320, 240, 16) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 160, 120, 16) 0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 160, 120, 16) 0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 160, 120, 32) 4640        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 160, 120, 32) 128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 160, 120, 32) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 160, 120, 32) 9248        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 160, 120, 32) 128         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 160, 120, 32) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 80, 60, 32)   0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 80, 60, 32)   0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 80, 60, 64)   18496       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 80, 60, 64)   256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 80, 60, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 80, 60, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 80, 60, 64)   256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 80, 60, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 40, 30, 64)   0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 40, 30, 64)   0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 40, 30, 128)  73856       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 40, 30, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 40, 30, 128)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 40, 30, 128)  147584      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 40, 30, 128)  512         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 40, 30, 128)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 20, 15, 128)  0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 20, 15, 128)  0           max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 20, 15, 256)  295168      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 20, 15, 256)  1024        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 20, 15, 256)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 20, 15, 256)  590080      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 20, 15, 256)  1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 20, 15, 256)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 40, 30, 128)  295040      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 40, 30, 256)  0           conv2d_transpose_1[0][0]         \n",
            "                                                                 activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 40, 30, 256)  0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 40, 30, 128)  295040      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 40, 30, 128)  512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 40, 30, 128)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 40, 30, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 40, 30, 128)  512         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 40, 30, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 80, 60, 64)   73792       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 80, 60, 128)  0           conv2d_transpose_2[0][0]         \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 80, 60, 128)  0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 80, 60, 64)   73792       dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 80, 60, 64)   256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 80, 60, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 80, 60, 64)   36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 80, 60, 64)   256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 80, 60, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 160, 120, 32) 18464       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 160, 120, 64) 0           conv2d_transpose_3[0][0]         \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 160, 120, 64) 0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 160, 120, 32) 18464       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 160, 120, 32) 128         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 160, 120, 32) 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 160, 120, 32) 9248        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 160, 120, 32) 128         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 160, 120, 32) 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 320, 240, 16) 4624        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 320, 240, 32) 0           conv2d_transpose_4[0][0]         \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 320, 240, 32) 0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 320, 240, 16) 4624        dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 320, 240, 16) 64          conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 320, 240, 16) 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 320, 240, 16) 2320        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 320, 240, 16) 64          conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 320, 240, 16) 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 320, 240, 1)  17          activation_18[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 2,164,593\n",
            "Trainable params: 2,161,649\n",
            "Non-trainable params: 2,944\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FHIqJ6NhkxXW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "844a647a-fbb2-4bf4-84c6-7eea2ecf427f"
      },
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "batch_size = 16\n",
        "\n",
        "print(train_images.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1193, 320, 240, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D_AujLkBliR9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "outputId": "bf0a8847-6748-474a-f5e5-18e95ac1f315"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(train_images, train_masks,\n",
        "                    validation_data=[[valid_images], [valid_masks]],\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[model_checkpoint, reduce_lr],#[early_stopping, reduce_lr],\n",
        "                    verbose=1)\n",
        "print('Fitted!')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1193 samples, validate on 298 samples\n",
            "Epoch 1/50\n",
            "  48/1193 [>.............................] - ETA: 36:02 - loss: 1.6761 - dice_coef_K: -0.7261"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-aab349e5ccc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#[early_stopping, reduce_lr],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fitted!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DacVuWBLliPr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "di__4dP-sFww",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict_result(model ,x_test ,img_size_target): # predict both orginal and reflect x\n",
        "    x_test_reflect = np.array([np.fliplr(x) for x in x_test])\n",
        "    x_test_reflect = x_test_reflect\n",
        "    print('Predicting...')\n",
        "    preds_test1 = model.predict(x_test, verbose=1)  # .reshape(-1, img_size_target[0], img_size_target[1])\n",
        "    # preds_test2_refect = model.predict(x_test_reflect).reshape(-1, img_size_target[0], img_size_target[1])\n",
        "    # preds_test2 = np.array([ np.fliplr(x) for x in preds_test2_refect] )\n",
        "    # preds_avg = (preds_test1 + preds_test2)/2\n",
        "    # return preds_avg\n",
        "    return preds_test1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jil2RTO4sFux",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set some parameters\n",
        "im_width = 101\n",
        "im_height = 101\n",
        "im_chan = 1\n",
        "img_size_ori = (320, 240)\n",
        "img_size_target = (320, 240)\n",
        "\n",
        "test_dir = '../data/test/'\n",
        "test_images = np.array([np.array(load_img(join(test_dir, f), grayscale=False)) / 255\n",
        "                        for f in listdir(test_dir) if isfile(join(test_dir, f))])\n",
        "test_file_names = [f[:f.find('.')] for f in listdir(test_dir) if isfile(join(test_dir, f))]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bt8_4uissFss",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# лучшая - resnet_weights.17--0.95.hdf5\n",
        "# unet_weights.23-val_loss0.12--0.95.hdf5.model - более-менее\n",
        "# unet_weights.49-val_loss0.12--0.96.hdf5.model - лучшая из unet\n",
        "model_name = '../models/unet_weights.49-val_loss0.12--0.96.hdf5.model'\n",
        "print('Loading model: {}'.format(model_name))\n",
        "model = load_model(model_name, # unet_weights.11-val_loss0.12--0.95.hdf5.model\n",
        "                   custom_objects={'dice_coef_K': dice_coef_K, 'my_dice_metric': my_dice_metric})\n",
        "valid_images = test_images#[:10]\n",
        "\n",
        "pred_masks = predict_result(model, valid_images, img_size_target)\n",
        "# save initial image\n",
        "for i, mask in enumerate(pred_masks):\n",
        "    # Initial image\n",
        "    initial_im = Image.fromarray((valid_images[i] * 255).astype(np.uint8))\n",
        "    initial_im.save(\"../output/unet/{}_initial.png\".format(test_file_names[i]))\n",
        "\n",
        "    # Mask\n",
        "    pred_mask = (pred_masks[i]).reshape((320, 240))\n",
        "    pred_mask = np.round(pred_mask) * 255\n",
        "    pred_mask = pred_mask.astype(np.uint8)\n",
        "    # try_one_image = try_one_image.reshape((try_one_image.shape[0], try_one_image.shape[1], 1))\n",
        "    new_p = Image.fromarray(pred_mask)\n",
        "    new_p.save(\"../output/unet/{}_mask.png\".format(test_file_names[i]))\n",
        "\n",
        "    val_image = valid_images[i].copy()\n",
        "    val_image = np.round(val_image * 255, 0).astype(np.uint8)\n",
        "\n",
        "    # Возможно, это особенности работы функций opencv. В этом пакете кодировка BGR вместо RGB\n",
        "    val_image = np.concatenate([val_image[:, :, 2].reshape(val_image.shape[:2] + (1,)),\n",
        "                                val_image[:, :, 1].reshape(val_image.shape[:2] + (1,)),\n",
        "                                val_image[:, :, 0].reshape(val_image.shape[:2] + (1,))], axis=2)\n",
        "    pred_mask_red = np.zeros(pred_mask.shape + (3,), np.uint8)\n",
        "    pred_mask_red[:, :, 2] = pred_mask.copy()\n",
        "    blended_image = cv2.addWeighted(pred_mask_red, 1, val_image, 1, 0)\n",
        "    cv2.imwrite('../output/unet/{}_image_plus_mask.png'.format(test_file_names[i]), blended_image)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cYM9j7hAsFql",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-bjd1kD1sVLT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "inAqx-REsVJT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from keras.preprocessing.image import load_img#,save_img\n",
        "from os.path import isfile, join\n",
        "from matplotlib.pyplot import subplots_adjust\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# %matplotlib inline\n",
        "\n",
        "SIZE_OF_RANDOM_CHOOSE = 7\n",
        "# Считыавем тестовые изображения:\n",
        "test_dir = 'new'\n",
        "test_images = np.array([np.array(load_img(join(test_dir, f), grayscale=False)) / 255\n",
        "                        for f in listdir(test_dir) if isfile(join(test_dir, f))])\n",
        "test_file_names = [f[:f.find('.')] for f in listdir(test_dir) if isfile(join(test_dir, f))]\n",
        "test_file_names, test_images = zip(*sorted(zip(test_file_names, test_images)))\n",
        "\n",
        "# Выбираем рандомно несколько изображений:\n",
        "temp_ = np.array(list(range(0, len(test_file_names)))).reshape((-1, 3))\n",
        "b = temp_[np.random.choice(temp_.shape[0], SIZE_OF_RANDOM_CHOOSE, replace=False), :].flatten()\n",
        "random_choose_test_file_names = np.array(test_file_names)[b]\n",
        "random_choose_test_images = np.array(test_images)[b]\n",
        "\n",
        "fig = plt.figure(figsize=(15, 26))\n",
        "#fig.tight_layout()\n",
        "\n",
        "subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0.1, wspace = 0)\n",
        "\n",
        "columns = 3\n",
        "rows = SIZE_OF_RANDOM_CHOOSE\n",
        "ax = []\n",
        "\n",
        "for i in range(columns*rows):\n",
        "    name = random_choose_test_file_names[i]\n",
        "    image = random_choose_test_images[i]\n",
        "    ax.append( fig.add_subplot(rows, columns, i+1) )\n",
        "    #ax[-1].set_title(\"ax:\"+str(i))  # set title\n",
        "    plt.imshow(image)\n",
        "\n",
        "#plt.subplots_adjust(wspace=0, hspace=0)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-5xmRDI2sVHI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PZSqMA72sVEK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "97J4wiZcsFn9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}