{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras import optimizers\n",
    "from keras.layers import DepthwiseConv2D\n",
    "#from keras_applications.mobilenet import relu6\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "PROJECT_PATH = os.getcwd()\n",
    "sys.path.append(PROJECT_PATH)\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from engine.tools.make_labels_csv import generate_labels_from_train\n",
    "from engine.tools.filesystem_functions import get_cardname, get_barcode_class\n",
    "from engine.tools.make_consolidation_df import consolidation_df_for_predictions\n",
    "from engine.tools.add_metrics import precision, recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_MODEL_FROM_LOGS = True\n",
    "name_of_models = ['mobilenet_1.00_224_1.h5']\n",
    "args = {'input_path': os.path.join(PROJECT_PATH, 'data', 'TEMP_CODE', 'test'), \n",
    "        'train_path': os.path.join(PROJECT_PATH, 'data', 'TEMP_CODE')}\n",
    "\n",
    "\"\"\" Set paths for project, model to be used, input data, train data and output data\"\"\"\n",
    "TRAIN_DATA_PATH = args['train_path']\n",
    "barcode = get_barcode_class(TRAIN_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_path': 'C:\\\\Users\\\\ddenisov\\\\JupyterProjects\\\\Cards_folder\\\\data\\\\TEMP_CODE\\\\test',\n",
       " 'train_path': 'C:\\\\Users\\\\ddenisov\\\\JupyterProjects\\\\Cards_folder\\\\data\\\\TEMP_CODE'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2447 images belonging to 10 classes.\n",
      "Found 24 images belonging to 1 classes.\n",
      "24/24 [==============================] - ETA: 35 - ETA: 21 - ETA: 16 - ETA: 14 - ETA: 12 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 11s 438ms/step\n"
     ]
    }
   ],
   "source": [
    "for name_of_model in name_of_models:\n",
    "    if LOAD_MODEL_FROM_LOGS:\n",
    "        args['model'] = name_of_model\n",
    "        MODEL_PATH = os.path.join(PROJECT_PATH, 'models', barcode, name_of_model) #!!!!!!!!!!!!!!!!\n",
    "    else:\n",
    "        MODEL_PATH = os.path.join(PROJECT_PATH, 'models', barcode, args['model'])\n",
    "    INPUT_PATH = args['input_path']\n",
    "    OUTPUT_PATH = os.path.join(PROJECT_PATH, 'resource', barcode, 'results')\n",
    "    SUPPORT_FILES_PATH = os.path.join(PROJECT_PATH, 'resource', barcode, 'support_files')\n",
    "\n",
    "    \"\"\" Get labels names from the folder with train samples \"\"\"\n",
    "    if not os.path.exists(os.path.join(SUPPORT_FILES_PATH, 'labels.csv')):\n",
    "        generate_labels_from_train(TRAIN_DATA_PATH, PROJECT_PATH)\n",
    "\n",
    "    \"\"\" Load and define model \"\"\"\n",
    "    with CustomObjectScope({'relu6': keras.layers.ReLU(6.), 'DepthwiseConv2D': DepthwiseConv2D}):\n",
    "        model = keras.models.load_model(MODEL_PATH, custom_objects={'precision': precision, 'recall': recall})\n",
    "    sgd = optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "    model.compile(optimizer=sgd,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    \"\"\" Initialize data generator for input data \"\"\"\n",
    "    test_datagen = image.ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        directory=INPUT_PATH,\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=1,\n",
    "        class_mode=None,\n",
    "        shuffle=False,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    \"\"\" Save input cardnames \"\"\"\n",
    "    test_generator.reset()\n",
    "    filenames = test_generator.filenames\n",
    "    cardnames = [get_cardname(filename) for filename in filenames]\n",
    "    with open(os.path.join(SUPPORT_FILES_PATH, 'cardnames.txt'), \"w\") as output:\n",
    "        output.write(' '.join(cardnames))\n",
    "\n",
    "    TRAIN_SOURCE = 'train_source' in args['input_path']\n",
    "    if TRAIN_SOURCE:\n",
    "        flag = os.path.exists(os.path.join(OUTPUT_PATH, 'predictions_with_all_probabilities_train_source_{}.csv'.format(args['model'][:-3])))\n",
    "    else:\n",
    "        flag = os.path.exists(os.path.join(OUTPUT_PATH, 'predictions_with_all_probabilities_{}.csv'.format(args['model'][:-3])))\n",
    "    \"\"\" Make predictions with the selected model \"\"\"\n",
    "    if not flag:\n",
    "        pred = model.predict_generator(test_generator, verbose=1)\n",
    "        \n",
    "        \"\"\" Save prediction results \"\"\"\n",
    "        if TRAIN_SOURCE:\n",
    "            np.savetxt(os.path.join(OUTPUT_PATH, 'predictions_with_all_probabilities_train_source_{}.csv'.format(args['model'][:-3])),pred,\n",
    "                delimiter=\",\")\n",
    "        else:\n",
    "            np.savetxt(os.path.join(OUTPUT_PATH, 'predictions_with_all_probabilities_{}.csv'.format(args['model'][:-3])), pred,\n",
    "                       delimiter=\",\")\n",
    "\n",
    "    \"\"\" Generate files with processed results \"\"\"\n",
    "    consolidation_df_for_predictions(args['model'], OUTPUT_PATH, SUPPORT_FILES_PATH, TRAIN_SOURCE)\n",
    "del pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
